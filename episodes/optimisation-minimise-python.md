---
title: "Minimise Python (Numpy/Pandas)"
teaching: 0
exercises: 0
---

:::::::::::::::::::::::::::::::::::::: questions

- 

::::::::::::::::::::::::::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::: objectives

- Able to identify when Python code can be rewritten to perform execution in the back-end.

::::::::::::::::::::::::::::::::::::::::::::::::

Python is an interpreted programming language. When you execute your `.py` file, the default CPython back-end compiles your Python source code to an intermediate bytecode. This bytecode is then interpreted in software at runtime generating instructions for the processor as necessary. This interpretation stage, and other features of the language, harm the performance of Python (whilst improving it's usability).

In comparison, many languages such as C/C++ compile directly to machine code. This allows them to better exploit hardware nuance to achieve fast performance, at the cost of compiled software not being cross-platform.

Whilst Python will rarely be as fast as compiled languages like C/C++, it is possible to take advantage of the CPython back-end and other libraries such as numpy and pandas that have been written in compiled languages to expose this performance.

A simple example of this would be to search a list.
The below example creates a list of 2500 integers in the inclusive-exclusive range `[0, 5000)`.
It then searches for all of the even numbers in that range.
`searchlistPython()` is implemented manually, iterating `ls` checking each individual item in Python code.
`searchListC()` in contrast uses the `in` operator to perform each search, which allows CPython to implement the inner loop in it's C back-end.

```python
import random

N = 2500  # Number of elements in list
M = 2  # N*M == Range over which the elements span

def generateInputs():
    random.seed(12)  # Ensure every list is the same
    return [random.randint(0, int(N*M)) for i in range(N)]
    
def searchListPython():
    ls = generateInputs()
    ct = 0
    for i in range(0, int(N*M), M):
        for j in range(0, len(ls)):
            if ls[j] == i:
                ct += 1
                break

def searchListC():
    ls = generateInputs()
    ct = 0
    for i in range(0, int(N*M), M):
        if i in ls:
            ct += 1

repeats = 1000
gen_time = timeit(generateInputs, number=repeats)
print(f"searchListPython: {timeit(searchListPython, number=repeats)-gen_time:.2f}ms")
print(f"searchListC: {timeit(searchListC, number=repeats)-gen_time:.2f}ms")
```

This results in the manual Python implementation being 5x slower, doing the exact same operation!

```output
searchListPython: 152.15ms
searchListC: 28.43ms
```

An easy approach to follow is that if two blocks of code do the same operation, the one that contains less Python is probably faster. This won't apply if you're using 3rd party packages written purely in Python though.

::::::::::::::::::::::::::::::::::::: callout

You can use `dis` to view the bytecode generated by Python, the amount of byte-code more strongly correlates with how much code is being executed by the Python interpreter. However, this still does not account for whether functions called are implemented using Python or C.

The pure Python search compiles to 82 lines of byte-code.

```python
import dis

def searchListPython():
    ls = generateInputs()
    ct = 0
    for i in range(0, int(N*M), M):
        for j in range(0, len(ls)):
            if ls[j] == i:
                ct += 1
                break

dis.dis(searchListPython)
```
```output
 11           0 LOAD_GLOBAL              0 (generateInputs)
              2 CALL_FUNCTION            0
              4 STORE_FAST               0 (ls)

 12           6 LOAD_CONST               1 (0)
              8 STORE_FAST               1 (ct)

 13          10 LOAD_GLOBAL              1 (range)
             12 LOAD_CONST               1 (0)
             14 LOAD_GLOBAL              2 (int)
             16 LOAD_GLOBAL              3 (N)
             18 LOAD_GLOBAL              4 (M)
             20 BINARY_MULTIPLY
             22 CALL_FUNCTION            1
             24 LOAD_GLOBAL              4 (M)
             26 CALL_FUNCTION            3
             28 GET_ITER
        >>   30 FOR_ITER                24 (to 80)
             32 STORE_FAST               2 (i)

 14          34 LOAD_GLOBAL              1 (range)
             36 LOAD_CONST               1 (0)
             38 LOAD_GLOBAL              5 (len)
             40 LOAD_FAST                0 (ls)
             42 CALL_FUNCTION            1
             44 CALL_FUNCTION            2
             46 GET_ITER
        >>   48 FOR_ITER                14 (to 78)
             50 STORE_FAST               3 (j)

 15          52 LOAD_FAST                0 (ls)
             54 LOAD_FAST                3 (j)
             56 BINARY_SUBSCR
             58 LOAD_FAST                2 (i)
             60 COMPARE_OP               2 (==)
             62 POP_JUMP_IF_FALSE       38 (to 76)

 16          64 LOAD_FAST                1 (ct)
             66 LOAD_CONST               2 (1)
             68 INPLACE_ADD
             70 STORE_FAST               1 (ct)

 17          72 POP_TOP
             74 JUMP_FORWARD             1 (to 78)

 15     >>   76 JUMP_ABSOLUTE           24 (to 48)
        >>   78 JUMP_ABSOLUTE           15 (to 30)

 13     >>   80 LOAD_CONST               0 (None)
             82 RETURN_VALUE
```

Whereas the `in` variant only compiles to 54.

```python
import dis

def searchListC():
    ls = generateInputs()
    ct = 0
    for i in range(0, int(N*M), M):
        if i in ls:
            ct += 1

dis.dis(searchListC)
```
```output
  4           0 LOAD_GLOBAL              0 (generateInputs)
              2 CALL_FUNCTION            0
              4 STORE_FAST               0 (ls)

  5           6 LOAD_CONST               1 (0)
              8 STORE_FAST               1 (ct)

  6          10 LOAD_GLOBAL              1 (range)
             12 LOAD_CONST               1 (0)
             14 LOAD_GLOBAL              2 (int)
             16 LOAD_GLOBAL              3 (N)
             18 LOAD_GLOBAL              4 (M)
             20 BINARY_MULTIPLY
             22 CALL_FUNCTION            1
             24 LOAD_GLOBAL              4 (M)
             26 CALL_FUNCTION            3
             28 GET_ITER
        >>   30 FOR_ITER                10 (to 52)
             32 STORE_FAST               2 (i)

  7          34 LOAD_FAST                2 (i)
             36 LOAD_FAST                0 (ls)
             38 CONTAINS_OP              0
             40 POP_JUMP_IF_FALSE       25 (to 50)

  8          42 LOAD_FAST                1 (ct)
             44 LOAD_CONST               2 (1)
             46 INPLACE_ADD
             48 STORE_FAST               1 (ct)
        >>   50 JUMP_ABSOLUTE           15 (to 30)

  6     >>   52 LOAD_CONST               0 (None)
             54 RETURN_VALUE
```

:::::::::::::::::::::::::::::::::::::::::::::

## Functional Operators

In order to take advantage of offloading computation to the CPython back-end it's necessary to be aware of what functionality is present. Those available without importing packages are considered [built-in](https://docs.python.org/3/library/functions.html) functions.

In particular, those which are passed an `iterable` are likely to provide the greatest benefits to performance. The Python documentation provides equivalent Python code for many of these cases

* [`all()`](https://docs.python.org/3/library/functions.html#all): boolean and of all items
* [`any()`](https://docs.python.org/3/library/functions.html#all): boolean or of all items
* [`filter()`](https://docs.python.org/3/library/functions.html#filter): Return an iterator of items that return true for the provided function
* [`map()`](https://docs.python.org/3/library/functions.html#map): Return an iterator that applies the provided function to ever item.
* [`max()`](https://docs.python.org/3/library/functions.html#max): Return the maximum item 
* [`min()`](https://docs.python.org/3/library/functions.html#min): Return the minimum item 
* [`sum()`](https://docs.python.org/3/library/functions.html#sum): Return the sum of all items
* [`zip()`](https://docs.python.org/3/library/functions.html#zip): Return an iterator which returns a tuple of items from each of the provided iterables.


Additionally the core package [`itertools`](https://docs.python.org/3/library/itertools.html) provide many advanced iterators such as [`accumulate()`](https://docs.python.org/3/library/itertools.html#itertools.accumulate) and [`functools`](https://docs.python.org/3/library/functools.html#module-functools) provides [`reduce()`](https://docs.python.org/3/library/functools.html#functools.reduce) for performing bespoke reductions over iterables.

<!-- todo exercise/s where pure-python must be converted to use one of the above fns. -->

## Using NumPy (Effectively)

NumPy is a commonly used package for scientific computing, which provides a wide variety of methods.

It adds restriction via it's own types, and static arrays to enable even greater performance than that of core Python. However, if these restrictions are ignored the performance can become significantly worse.

### Arrays

NumPy's arrays (not to be confused with the core Python `array` package) are static arrays. Unlike core Python's lists, they do not dynamically resize. Therefore if you wish to append to a NumPy array, you must call `resize()` first. If you treat this like `append()` for a Python list, resizing for each individual append you will be performing significantly more copies and memory allocations than a Python list.

<!-- todo short example of array resize sloww -->

Another difference, is that NumPy arrays require all data to be the same type (and a NumPy type). This enables more efficient access to elements, as they all exist contiguously in memory. In contrast, elements within Python lists can be of any type so the list always stores a pointer to where the element actually exists in memory, rather than the actual element. This has the side effect that if you are converting back and forth between Python lists and NumPy arrays, there is an additional overhead as it's not as simple as copying a single block of memory.

<!-- todo how can this be demonstrated?-->

### Numpy types

### Numpy functions

## Using Pandas (Effectively)

::::::::::::::::::::::::::::::::::::: keypoints

- 

::::::::::::::::::::::::::::::::::::::::::::::::
